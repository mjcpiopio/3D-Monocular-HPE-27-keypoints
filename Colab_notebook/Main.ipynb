{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT_I5P_NJRyR"
      },
      "source": [
        "# Hybrid Model for HPE - Estimation of 27 body keypoint positions for each frame of input videos, for further kinematic and inverse dynamic analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2h9Fko7oMpk"
      },
      "source": [
        "**Step 1 (VideoPose3D output) -** This code generates two output folders: *'output_videos_VideoPose3D'* and *'coordinates_VideoPose3D'*. Each folder contains individual subfolders for each subject. The *'output_videos_VideoPose3D'*  folders includes an `.mp4` animation of the predicted movements, while the *'coordinates_VideoPose3D'*  folders contains both `.npz` and `.txt` files that store the coordinates of 17 body keypoints for every frame of the corresponding input video, as predicted by VideoPose3D. Input videos should be placed in a designated folder, with each video filename containing a unique identifying number to distinguish between subjects. (Runtime Mode - *T4 GPU*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cydb4tpRH_ky"
      },
      "outputs": [],
      "source": [
        "#Import files from Google drive to Google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHBywgaufCVM"
      },
      "outputs": [],
      "source": [
        "#Install necessary libraries and imports.\n",
        "!pip install pillow==9.4.0 idna==3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhTw9KpvIOm9"
      },
      "outputs": [],
      "source": [
        "#Install necessary libraries and imports.\n",
        "\n",
        "import importlib\n",
        "\n",
        "#Install ffmpeg\n",
        "try:\n",
        "    importlib.import_module('ffmpeg')\n",
        "    print(\"ffmpeg is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"Installing ffmpeg...\")\n",
        "    !apt-get install ffmpeg -y\n",
        "\n",
        "#Install Detectron2\n",
        "try:\n",
        "    importlib.import_module('detectron2')\n",
        "    print(\"detectron2 is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"Installing detectron2...\")\n",
        "    !pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'\n",
        "\n",
        "#Install Opencv\n",
        "try:\n",
        "    importlib.import_module('cv2')\n",
        "    print(\"opencv-python is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"Installing opencv-python...\")\n",
        "    !pip install opencv-\n",
        "\n",
        "#Install torch 2.2\n",
        "try:\n",
        "    import torch\n",
        "    if torch.__version__ == '2.2.0':\n",
        "        print(\"torch 2.2 is already installed.\")\n",
        "    else:\n",
        "        raise ImportError\n",
        "except ImportError:\n",
        "    print(\"Installing torch 2.2...\")\n",
        "    !pip install torch==2.2.0 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "\n",
        "try:\n",
        "    importlib.import_module('glob')\n",
        "    print(\"glob is already imported.\")\n",
        "except ImportError:\n",
        "    print(\"Importing glob...\")\n",
        "    from glob import glob\n",
        "\n",
        "try:\n",
        "    importlib.import_module('sys')\n",
        "    print(\"sys is already imported.\")\n",
        "except ImportError:\n",
        "    print(\"Importing sys...\")\n",
        "    import sys\n",
        "\n",
        "try:\n",
        "    importlib.import_module('argparse')\n",
        "    print(\"argparse is already imported.\")\n",
        "except ImportError:\n",
        "    print(\"Importing argparse...\")\n",
        "    import argparse\n",
        "\n",
        "#Components of detectron2\n",
        "\n",
        "import torch, detectron2\n",
        "try:\n",
        "    nvcc_output = !nvcc --version\n",
        "    TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "    CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "    print(\"torch:\", TORCH_VERSION, \"; cuda:\", CUDA_VERSION)\n",
        "    print(\"detectron2:\", detectron2.__version__)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "import json\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "%matplotlib inline\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    GPU = True\n",
        "    print('GPU available')\n",
        "else:\n",
        "    GPU = False\n",
        "    print('No GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZcIF7wJhwI7"
      },
      "outputs": [],
      "source": [
        "#Install necessary libraries and imports.\n",
        "!pip install tqdm==4.66.1 tensorboard==2.15.1 platformdirs==4.1.0 numpy==1.23.5 fonttools==4.46.0 grpcio==1.60.0 google-auth==2.17.3 markdown==3.5.1 huggingface_hub==0.19.4 safetensors==0.4.1 typing-extensions==4.5.0 jinja2==3.1.2 MarkupSafe==2.1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvweP8bSJFGy"
      },
      "outputs": [],
      "source": [
        "#Change directory to the VideoPose3D folder\n",
        "\n",
        "main_directory = '/content/drive/MyDrive/VideoPose3D'\n",
        "\n",
        "#Change the current working directory to the desired directory\n",
        "os.chdir(main_directory)\n",
        "\n",
        "#Verify current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "print(\"Current Working Directory:\", current_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qiy4bGuKk5Ay"
      },
      "outputs": [],
      "source": [
        "#If this cell fails to run, please try running the cells above again\n",
        "#Get the path of the folder containing input videos\n",
        "folder_videos = input(\"Enter the path of the folder containing the input video files: \")\n",
        "\n",
        "#Check if the folder exists\n",
        "if not os.path.exists(folder_videos) or not os.path.isdir(folder_videos):\n",
        "    print(f\"The folder '{folder_videos}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "# Current working directory - the directory of the VideoPose3D folder\n",
        "folder_path = os.getcwd()\n",
        "\n",
        "# Create 'detections' folder in /content directory\n",
        "folder_detections = 'detections'\n",
        "path_detections = os.path.join('/content', folder_detections)\n",
        "if not os.path.exists(path_detections):\n",
        "    os.makedirs(path_detections)\n",
        "    print(f\"The folder '{path_detections}' was created.\")\n",
        "else:\n",
        "    print(f\"The folder '{path_detections}' already exists.\")\n",
        "\n",
        "# Create 'output_videos' folder in /content directory\n",
        "folder_output = 'output_videos_VideoPose3D'\n",
        "path_output = os.path.join('/content', folder_output)\n",
        "if not os.path.exists(path_output):\n",
        "    os.makedirs(path_output)\n",
        "    print(f\"The folder '{path_output}' was created.\")\n",
        "else:\n",
        "    print(f\"The folder '{path_output}' already exists.\")\n",
        "\n",
        "# Create 'coordinates' folder in /content directory\n",
        "folder_coordinates = 'coordinates_VideoPose3D'\n",
        "path_coordinates = os.path.join('/content', folder_coordinates)\n",
        "if not os.path.exists(path_coordinates):\n",
        "    os.makedirs(path_coordinates)\n",
        "    print(f\"The folder '{path_coordinates}' was created.\")\n",
        "else:\n",
        "    print(f\"The folder '{path_coordinates}' already exists.\")\n",
        "\n",
        "#inferring 2D keypoints with detectron2\n",
        "path_inference = os.path.join(folder_path, 'inference', 'infer_video_d2.py')\n",
        "!python \"{path_inference}\" \\\n",
        "  --cfg COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml \\\n",
        "  --output-dir \"{path_detections}\" \\\n",
        "  --image-ext mp4 \\\n",
        "  \"{folder_videos}\"  # directory of the folder with input videos\n",
        "\n",
        "#Creating a custom dataset\n",
        "path_data = os.path.join(folder_path, 'data')\n",
        "%cd \"{path_data}\"\n",
        "!python prepare_data_2d_custom.py -i \"{path_detections}\" -o myvideos\n",
        "\n",
        "#Video/Animation with estimated 3D coordinates\n",
        "%cd \"{folder_path}\"\n",
        "\n",
        "file_names = []\n",
        "\n",
        "for filename in os.listdir(folder_videos): #Loop through the filenames in the input folder. Ensure each file has a unique number for identification\n",
        "    if filename.startswith('.') or filename.endswith('.txt'):  # Skip non-video files.\n",
        "        continue\n",
        "\n",
        "    #Extract number from the filename\n",
        "    number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "    #Name for the output folders of each subject\n",
        "    output_folder = f'subject_{number}'\n",
        "    coordinates_folder = f'subject_{number}'\n",
        "\n",
        "    #Name for the output files of each subject\n",
        "    output_filename = f'output_{number}.mp4'\n",
        "    coordinates_filename = f'coordinates_{number}.npy'\n",
        "\n",
        "    #Creating individual subject folders in the 'output_videos' folder\n",
        "    path_output_subject = os.path.join(path_output, output_folder)\n",
        "    if not os.path.exists(path_output_subject):\n",
        "        os.makedirs(path_output_subject)\n",
        "        print(f\"The folder '{path_output_subject}' was created.\")\n",
        "\n",
        "    # creating individual subject folders in the 'coordinates' folder\n",
        "    path_coordinates_subject = os.path.join(path_coordinates, coordinates_folder)\n",
        "    if not os.path.exists(path_coordinates_subject):\n",
        "        os.makedirs(path_coordinates_subject)\n",
        "        print(f\"The folder '{path_coordinates_subject}' was created.\")\n",
        "\n",
        "    file_names.append(filename)\n",
        "\n",
        "    command1 = f'python run.py -d custom -k myvideos -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_detectron_coco.bin --render --viz-subject {filename} --viz-action custom --viz-camera 0 --viz-video \"{os.path.join(folder_videos, filename)}\" --viz-output \"{os.path.join(path_output_subject, output_filename)}\" --viz-size 6'\n",
        "    command2 = f'python run.py -d custom -k myvideos -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_detectron_coco.bin --render --viz-subject {filename} --viz-action custom --viz-camera 0 --viz-video \"{os.path.join(folder_videos, filename)}\" --viz-export \"{os.path.join(path_coordinates_subject, coordinates_filename)}\" --viz-size 6'\n",
        "\n",
        "    print(f'Executing command: {command1}')\n",
        "    print(f'Executing command: {command2}')\n",
        "\n",
        "    try:\n",
        "        os.system(command1)\n",
        "        os.system(command2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error occurred: {e}')\n",
        "\n",
        "#Convert npz file to txt file\n",
        "for filename in file_names:\n",
        "  number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "  npz_file = os.path.join(path_coordinates, f'subject_{number}', f'coordinates_{number}.npy')\n",
        "  txt_output_file = os.path.join(path_coordinates, f'subject_{number}', f'coordinates_{number}.txt')\n",
        "\n",
        "  try:\n",
        "        np.set_printoptions(threshold=np.inf)  #To keep all values of the array\n",
        "        data = np.load(npz_file)\n",
        "        precision = 8\n",
        "\n",
        "        with open(txt_output_file, \"w\") as f:\n",
        "            for frame_index, frame in enumerate(data, start=1):  #Indicates the number of frames (starts by 1)\n",
        "                f.write(f\"Frame {frame_index}:\\n\")\n",
        "                for keypoint_index, keypoint in enumerate(frame, start=1):  #17 keypoints per frame\n",
        "                    keypoint_str = np.array2string(keypoint, precision=precision, separator=', ', floatmode='fixed')\n",
        "                    f.write(f\"Keypoint {keypoint_index}: {keypoint_str}\\n\")\n",
        "\n",
        "        print(f\"Converted {npz_file} to {txt_output_file}\")\n",
        "  except Exception as e:\n",
        "        print(f\"Error converting {npz_file}: {e}\")\n",
        "\n",
        "\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDJ9zZBKKS0O"
      },
      "source": [
        "**Step 2 (MediaPipe Pose output) -** This code generates an output folder (*'coordinates_MediaPipePose'*) containing individual subfolders for each subject. Inside each subject's folder, a `.txt` file is created that stores the coordinates of 33 body keypoints for every frame of the corresponding input video, as predicted by MediaPipe Pose. The input videos must be placed in a designated folder, and each video filename should include a unique number to distinguish between subjects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrVtvu-dKiP7"
      },
      "outputs": [],
      "source": [
        "#Installations necessary for MediaPipe Pose\n",
        "#If the session crashes, please run this cell again to ensure all dependencies are installed.\n",
        "\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install numpy==1.19.3\n",
        "!pip install -q mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j-sr8AQKjRk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mediapipe as mp\n",
        "\n",
        "#Initialize MediaPipe Pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "#Function to print the coordinates of the 33 keypoints for each frame (to disable printing the body landmarks for each frame, comment out the call to this function below)\n",
        "#def write_landmarks_to_csv(landmarks, frame_number, csv_data):\n",
        "#    print(f\"Landmark coordinates for frame {frame_number}:\")\n",
        "#    for idx, landmark in enumerate(landmarks):\n",
        "#        print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
        "#        csv_data.append([frame_number, mp_pose.PoseLandmark(idx).name, landmark.x, landmark.y, landmark.z])\n",
        "#    print(\"\\n\")\n",
        "\n",
        "#Specify the directory of the folder with the input files (videos)\n",
        "folder_videos = input(\"Enter the path of the folder containing the input video files: \")\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_videos) or not os.path.isdir(folder_videos):\n",
        "    print(f\"The folder '{folder_videos}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "# Create 'output_videos' folder in /content directory\n",
        "folder_output = 'coordinates_MediaPipePose'\n",
        "path_output = os.path.join('/content', folder_output)\n",
        "if not os.path.exists(path_output):\n",
        "    os.makedirs(path_output)\n",
        "    print(f\"The folder '{path_output}' was created.\")\n",
        "else:\n",
        "    print(f\"The folder '{path_output}' already exists.\")\n",
        "\n",
        "file_names = []\n",
        "\n",
        "for filename in os.listdir(folder_videos): #Loop through the filenames in the input folder. Ensure each file has a unique number for identification\n",
        "    if filename.startswith('.') or filename.endswith('.txt'):  # Skip non-video files.\n",
        "        continue\n",
        "\n",
        "    #Extract number from the filename\n",
        "    number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "    #Create an output folder for each subject (based on the number)\n",
        "    output_folder = f'subject_{number}'\n",
        "    path_output_subject = os.path.join(path_output, output_folder)\n",
        "    if not os.path.exists(path_output_subject):\n",
        "        os.makedirs(path_output_subject)\n",
        "        print(f\"The folder '{path_output_subject}' was created.\")\n",
        "    else:\n",
        "        print(f\"The folder '{path_output_subject}' already exists.\")\n",
        "\n",
        "    file_names.append(filename)\n",
        "\n",
        "# Process each video\n",
        "for filename in file_names:\n",
        "\n",
        "  file_path = os.path.join(folder_videos, filename)\n",
        "\n",
        "  # Open the video file\n",
        "  cap = cv2.VideoCapture(file_path)\n",
        "\n",
        "  # Extract the number from the filename\n",
        "  number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "  # Create the output .txt file for a given subject\n",
        "  output_file_txt = os.path.join(path_output, f'subject_{number}', f'coordinates_{number}.txt')\n",
        "\n",
        "  frame_number = 0\n",
        "  csv_data = []\n",
        "\n",
        "  # Create a list to store the keypoints positions for the entire video\n",
        "  keypoints_position_list = []\n",
        "\n",
        "  # Loop through each frame of the video\n",
        "  while cap.isOpened():\n",
        "      # Read a frame from the video\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break  # Break the loop if no frame read\n",
        "\n",
        "      # Convert the frame to RGB\n",
        "      image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Process the frame with MediaPipe Pose\n",
        "      result = pose.process(image)\n",
        "\n",
        "      if result.pose_world_landmarks:\n",
        "          keypoints_position_list.append(result.pose_world_landmarks) #Save the keypoints for the frame\n",
        "          #mp_drawing.draw_landmarks(frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS) # Draw landmarks on the frame (comment the line below if you don't want to display landmarks)\n",
        "          #write_landmarks_to_csv(result.pose_world_landmarks.landmark, frame_number, csv_data) # Print the keypoint coordinates for the frame (comment the line below to disable printing)\n",
        "\n",
        "\n",
        "      #Display the frame (comment this line if you don't want to show the frames while processing).\n",
        "      #cv2_imshow(frame)\n",
        "\n",
        "      # Save the keypoints of all frames in a txt file\n",
        "      with open(output_file_txt, \"w\") as f:\n",
        "          for frame_index, frame_landmarks in enumerate(keypoints_position_list, start=1): #Indicates the number of frames (starts by 1)\n",
        "              print(f\"Frame {frame_index}:\", file=f)\n",
        "              for keypoint_index, landmark in enumerate(frame_landmarks.landmark, start=1): #33 keypoints per frame\n",
        "                  print(f\"Keypoint {keypoint_index}: [{landmark.x}, {landmark.y}, {landmark.z}]\", file=f)\n",
        "\n",
        "      frame_number += 1\n",
        "\n",
        "      # Exit if 'q' key pressed\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1H9PZlZPTHS"
      },
      "source": [
        "**Step 3 -** Calculation of additional body keypoints - IJ, PX, EM, EL, RS, US, AC. Output: `.txt` files with the coordinates of each keypoint for all the frames of the input videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxxktsSwKkk8"
      },
      "outputs": [],
      "source": [
        "#function that gets the coordinates of each keypoint\n",
        "import numpy as np\n",
        "def get_coordinates(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    coordinates_txt = {} #dictionary with the number of frames, and the number of keypoints\n",
        "\n",
        "    frame_number = None\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith(\"Frame\"):\n",
        "            frame_number = int(line.split()[1].strip(':'))  #\"split\" to separate the different components and \"strip\" removes the colon, white spaces\n",
        "            coordinates_txt[frame_number] = {}\n",
        "        elif line.startswith(\"Keypoint\"):\n",
        "            parts = line.strip().split()\n",
        "            keypoint_number = int(parts[1].strip(':'))\n",
        "            coordinates = [float(coord.strip('[],')) for coord in parts[2:] if coord.strip('[],')] #remove square brackets and commas, convert to float\n",
        "            coordinates_txt[frame_number][keypoint_number] = coordinates\n",
        "\n",
        "    return coordinates_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHa2Ar-TQHfU"
      },
      "outputs": [],
      "source": [
        "#function that converts global to local coordinates\n",
        "\n",
        "def glob_2_loc_coords_3D(pointP, origin, basis_P1, basis_P2, basis_P3):\n",
        "    v1 = basis_P2 - basis_P1\n",
        "    v2 = basis_P3 - basis_P1\n",
        "\n",
        "    v1_norm = v1 / np.linalg.norm(v1)\n",
        "    v2_norm = v2 / np.linalg.norm(v2)\n",
        "\n",
        "    v3_norm = (np.cross(v1_norm, v2_norm)) / np.linalg.norm(np.cross(v1_norm, v2_norm))\n",
        "\n",
        "    v4_norm = (np.cross(v1_norm, v3_norm)) / np.linalg.norm(np.cross(v1_norm, v3_norm))\n",
        "\n",
        "    basis = np.array([[v1_norm[0], v3_norm[0], v4_norm[0]],\n",
        "                      [v1_norm[1], v3_norm[1], v4_norm[1]],\n",
        "                      [v1_norm[2], v3_norm[2], v4_norm[2]]])\n",
        "\n",
        "    return (basis.T).dot(pointP - origin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZPw0k6voFqK"
      },
      "outputs": [],
      "source": [
        "#function that converts local to global coordinates\n",
        "\n",
        "def loc_2_glob_coords_3D(loc_coords, origin, basis_P1, basis_P2, basis_P3):\n",
        "\n",
        "    global_coordinates = np.zeros((basis_P1.shape[0], 3))\n",
        "\n",
        "    if basis_P1.shape[0] == basis_P2.shape[0] == basis_P3.shape[0]:\n",
        "        v1 = basis_P2 - basis_P1\n",
        "        v2 = basis_P3 - basis_P1\n",
        "\n",
        "        v1_norm = v1 / np.linalg.norm(v1)\n",
        "        v2_norm = v2 / np.linalg.norm(v2)\n",
        "\n",
        "        v3_norm = (np.cross(v1_norm, v2_norm)) / np.linalg.norm(np.cross(v1_norm, v2_norm))\n",
        "\n",
        "        v4_norm = (np.cross(v1_norm, v3_norm)) / np.linalg.norm(np.cross(v1_norm, v3_norm))\n",
        "\n",
        "        basis = np.array([[v1_norm[0], v3_norm[0], v4_norm[0]],\n",
        "                          [v1_norm[1], v3_norm[1], v4_norm[1]],\n",
        "                          [v1_norm[2], v3_norm[2], v4_norm[2]]])\n",
        "\n",
        "        return origin + basis.dot(loc_coords)\n",
        "\n",
        "    else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZgJPJ_uQHP6"
      },
      "outputs": [],
      "source": [
        "#folder with the subfolders with the .txt files of each input video generated by the VideoPose3D algorithm\n",
        "folder_keypoints = '/content/coordinates_VideoPose3D'\n",
        "\n",
        "# Use os.walk to traverse through all subdirectories and files\n",
        "for root, dirs, files in os.walk(folder_keypoints):\n",
        "    for filename in files:\n",
        "        if not filename.endswith('.txt'):\n",
        "            continue  # Skip non-txt files\n",
        "\n",
        "        keypoints_file_dynamic = os.path.join(root, filename)\n",
        "\n",
        "        # Check if the file exists and is a file\n",
        "        if not os.path.isfile(keypoints_file_dynamic):\n",
        "            print(f\"The .txt file '{keypoints_file_dynamic}' does not exist.\")\n",
        "            continue\n",
        "\n",
        "        # Read the coordinates from the .txt file\n",
        "        data = get_coordinates(keypoints_file_dynamic)\n",
        "\n",
        "        # Generate a static trial - first 20 frames of the input video\n",
        "        output_file = os.path.join(root, f'static_{filename}')  # Save the static trial in the same subfolder as the dynamic trial\n",
        "\n",
        "        with open(output_file, 'w') as f:\n",
        "            for frame_number in range(1, 21):\n",
        "                if frame_number in data:\n",
        "                    f.write(f\"Frame {frame_number}:\\n\")\n",
        "                    coords = data[frame_number]\n",
        "                    for keypoint_number in sorted(coords.keys()):\n",
        "                        coordinates = coords[keypoint_number]\n",
        "                        coords_str = ' '.join(map(str, coordinates))\n",
        "                        f.write(f\"Keypoint {keypoint_number}: [{coords_str}]\\n\")\n",
        "\n",
        "        print(f\"Static trial for {filename} written to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3A7W_zloshJ"
      },
      "outputs": [],
      "source": [
        "folder_keypoints = '/content/coordinates_VideoPose3D'\n",
        "\n",
        "#calculate IJ and PX for the frames of the static trial\n",
        "for root, dirs, files in os.walk(folder_keypoints):\n",
        "    for filename in files:\n",
        "        if filename.startswith('static') and filename.endswith('.txt'):\n",
        "            static_file = os.path.join(root, filename)\n",
        "            number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "            keypoints_data = get_coordinates(static_file)\n",
        "\n",
        "\n",
        "            local_coordinates_list_IJ = []\n",
        "            local_coordinates_list_PX = []\n",
        "\n",
        "            #IJ keypoint\n",
        "            for frame_number, keypoints in keypoints_data.items():\n",
        "                spine = np.array(keypoints[8])\n",
        "                shoulder_right = np.array(keypoints[15])\n",
        "                shoulder_left = np.array(keypoints[12])\n",
        "                hip_right = np.array(keypoints[2])\n",
        "                hip_left = np.array(keypoints[5])\n",
        "                mid_shoulder = (shoulder_right + shoulder_left) / 2\n",
        "                mid_hip = (hip_right + hip_left) / 2\n",
        "                C7_global = np.array(keypoints[9])\n",
        "                vector1 = shoulder_left - shoulder_right\n",
        "                vector2 = spine - shoulder_right\n",
        "                vector1_unit = vector1 / np.linalg.norm(vector1)\n",
        "                vector2_unit = vector2 / np.linalg.norm(vector2)\n",
        "                normal_vector = -np.cross(vector1_unit, vector2_unit) #vector perpendicular to the plane formed by the two shoulders and spine (T8), pointing forward\n",
        "                normal_vector_unit = normal_vector / np.linalg.norm(normal_vector) #transform to unit vector\n",
        "                normal_vector_1 = normal_vector_unit * ((np.linalg.norm(C7_global - shoulder_right) * 0.1079) / 0.1887) #ratio between the distance from IJ to C7 and the distance from C7 to shoulder\n",
        "                IJ_global = C7_global + normal_vector_1\n",
        "\n",
        "                keypoints_data[frame_number][18] = IJ_global\n",
        "\n",
        "                #convert to local coordinates\n",
        "                IJ_local = glob_2_loc_coords_3D(IJ_global, mid_hip, mid_hip, spine, hip_right)\n",
        "\n",
        "                #save local coordinates for all frames of the static test in a list\n",
        "                local_coordinates_list_IJ.append(IJ_local)\n",
        "\n",
        "            local_coordinates_array_IJ = np.array(local_coordinates_list_IJ)\n",
        "\n",
        "            #calculate the average\n",
        "            IJ_local_final = np.mean(local_coordinates_array_IJ, axis=0)\n",
        "\n",
        "\n",
        "            #PX keypoint\n",
        "            for frame_number, keypoints in keypoints_data.items():\n",
        "                spine = np.array(keypoints[8])\n",
        "                shoulder_right = np.array(keypoints[15])\n",
        "                shoulder_left = np.array(keypoints[12])\n",
        "                hip_right = np.array(keypoints[2])\n",
        "                hip_left = np.array(keypoints[5])\n",
        "                mid_shoulder = (shoulder_right + shoulder_left) / 2\n",
        "                mid_hip = (hip_right + hip_left) / 2\n",
        "                IJ_global = np.array(keypoints[18])\n",
        "                C7_global = np.array(keypoints[9])\n",
        "                theta2 = 36.6823 #angle between vector C7-IJ and vector C7-PX\n",
        "                theta_rad2 = np.deg2rad(theta2) #change to radians\n",
        "                vector_sag_1 = IJ_global - C7_global\n",
        "                vector_sag_2 = spine - C7_global\n",
        "                vector_sag_1_unit = vector_sag_1 / np.linalg.norm(vector_sag_1)\n",
        "                vector_sag_2_unit = vector_sag_2 / np.linalg.norm(vector_sag_2)\n",
        "                vector_perp = np.cross(vector_sag_1_unit, vector_sag_2_unit) #vector perpendicular to the sagittal plane (IJ, C7 and spine(T8))\n",
        "                vector_perp_unit = vector_perp / np.linalg.norm(vector_perp) #unit vector\n",
        "\n",
        "                #rotation using Rodrigues' Rotation Formula\n",
        "                cos_theta2 = np.cos(theta_rad2)\n",
        "                sin_theta2 = np.sin(theta_rad2)\n",
        "                omega_x, omega_y, omega_z = vector_perp_unit\n",
        "\n",
        "                rotation_matrix1 = np.array([[cos_theta2 + omega_x**2 * (1 - cos_theta2), omega_x * omega_y * (1 - cos_theta2) - omega_z * sin_theta2, omega_x * omega_z * (1 - cos_theta2) + omega_y * sin_theta2],\n",
        "                    [omega_y * omega_x * (1 - cos_theta2) + omega_z * sin_theta2, cos_theta2 + omega_y**2 * (1 - cos_theta2), omega_y * omega_z * (1 - cos_theta2) - omega_x * sin_theta2],\n",
        "                    [omega_z * omega_x * (1 - cos_theta2) - omega_y * sin_theta2, omega_z * omega_y * (1 - cos_theta2) + omega_x * sin_theta2, cos_theta2 + omega_z**2 * (1 - cos_theta2)]])\n",
        "\n",
        "                vector_C7_PX = np.dot(rotation_matrix1, vector_sag_1_unit) #C7-IJ vector rotation\n",
        "                vector_C7_PX_unit = vector_C7_PX / np.linalg.norm(vector_C7_PX) #unit vector\n",
        "                vector5 = vector_C7_PX_unit * ((np.linalg.norm(C7_global - shoulder_right) * 0.2684) / 0.1887) #ratio between the distance from C7 to PX and the distance from C7 to SJC (C7 to the shoulder)\n",
        "\n",
        "                PX_global = C7_global + vector5\n",
        "\n",
        "                keypoints_data[frame_number][19] = PX_global\n",
        "\n",
        "                #convert to local coordinates\n",
        "                PX_local = glob_2_loc_coords_3D(PX_global, mid_hip, mid_hip, spine, hip_right)\n",
        "\n",
        "                #save local coordinates for all frames of the static test in a list\n",
        "                local_coordinates_list_PX.append(PX_local)\n",
        "\n",
        "            local_coordinates_array_PX = np.array(local_coordinates_list_PX)\n",
        "\n",
        "            #calculate the average\n",
        "            PX_local_final = np.mean(local_coordinates_array_PX, axis=0)\n",
        "\n",
        "            # Save the calculated keypoints in the static file\n",
        "            with open(static_file, 'w') as f:\n",
        "                for frame_number, keypoints in keypoints_data.items():\n",
        "                    f.write(f\"Frame {frame_number}:\\n\")\n",
        "                    for keypoint_number, coordinates in keypoints.items():\n",
        "                        f.write(f\"Keypoint {keypoint_number}: {coordinates}\\n\")\n",
        "\n",
        "            print(f\"New keypoints added to: {static_file}\")\n",
        "\n",
        "            # Find and process the corresponding dynamic file\n",
        "            for file in files:\n",
        "                if not file.startswith('static') and file.endswith('.txt'):\n",
        "                    dynamic_number = re.search(r'\\d+', file).group()\n",
        "                    if number == dynamic_number:\n",
        "                        dynamic_file = os.path.join(root, file)\n",
        "                        break\n",
        "\n",
        "            if dynamic_file:\n",
        "                keypoints_data = get_coordinates(dynamic_file)\n",
        "\n",
        "                #use the local coordinates calculated in the static trial, in the dynamic trial\n",
        "                for frame_number, keypoints in sorted(keypoints_data.items()):\n",
        "                    spine = np.array(keypoints[8])\n",
        "                    hip_right = np.array(keypoints[2])\n",
        "                    hip_left = np.array(keypoints[5])\n",
        "                    mid_hip = (hip_right + hip_left) / 2\n",
        "\n",
        "                    keypoints_data[frame_number][18] = loc_2_glob_coords_3D(IJ_local_final, mid_hip, mid_hip, spine, hip_right)\n",
        "                    keypoints_data[frame_number][19] = loc_2_glob_coords_3D(PX_local_final, mid_hip, mid_hip, spine, hip_right)\n",
        "\n",
        "                # Save the calculated keypoints in the dynamic file\n",
        "                with open(dynamic_file, 'w') as f:\n",
        "                    for frame_number, keypoints in keypoints_data.items():\n",
        "                        f.write(f\"Frame {frame_number}:\\n\")\n",
        "                        for keypoint_number, coordinates in keypoints.items():\n",
        "                            f.write(f\"Keypoint {keypoint_number}: {coordinates}\\n\")\n",
        "\n",
        "                print(f\"New keypoints added to: {dynamic_file}\")\n",
        "\n",
        "print(\"Processing completed for all static and dynamic trials.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QHUxnBrPfm9"
      },
      "outputs": [],
      "source": [
        "folder_keypoints = '/content/coordinates_VideoPose3D'\n",
        "\n",
        "#folder with the subfolders with the .txt files of each input video generated by the MediaPipe Pose algorithm\n",
        "folder_keypoints_1 = '/content/coordinates_MediaPipePose'\n",
        "\n",
        "# Calculate EL, EM, RS, US, AC for the dynamic trial\n",
        "for root, dirs, files in os.walk(folder_keypoints):\n",
        "    for filename in files:\n",
        "        if not filename.startswith('static') and filename.endswith('.txt'):\n",
        "            dynamic_file = os.path.join(root, filename)\n",
        "            number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "            keypoints_data = get_coordinates(dynamic_file)\n",
        "\n",
        "            # Find corresponding dynamic file in MediaPipePose folder\n",
        "            for root1, dirs1, files1 in os.walk(folder_keypoints_1):\n",
        "                for filename1 in files1:\n",
        "                    number1 = re.search(r'\\d+', filename1).group()\n",
        "                    if not filename1.startswith('static') and filename1.endswith('.txt') and number1 == number:\n",
        "                        dynamic_file1 = os.path.join(root1, filename1)\n",
        "                        keypoints_data1 = get_coordinates(dynamic_file1)\n",
        "\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            # Right EL, EM\n",
        "                            shoulder_right = np.array(keypoints[15])\n",
        "                            elbow_right = np.array(keypoints[16])\n",
        "                            wrist_right = np.array(keypoints[17])\n",
        "\n",
        "                            vector1_right = shoulder_right - elbow_right\n",
        "                            vector1_right_unit = vector1_right / np.linalg.norm(vector1_right)\n",
        "                            vector2_right = wrist_right - elbow_right\n",
        "                            vector2_right_unit = vector2_right / np.linalg.norm(vector2_right)\n",
        "\n",
        "                            normal_vector_right = np.cross(vector1_right, vector2_right) #vector perpendicular to the plane formed by the right shoulder, elbow and wrist, pointing to the left\n",
        "                            normal_vector_right_unit = normal_vector_right / np.linalg.norm(normal_vector_right)\n",
        "\n",
        "                            normal_vector1_right = normal_vector_right_unit * ((np.linalg.norm(shoulder_right - elbow_right) * (0.0632 / 2)) / 0.2655) #ratio between half the distance from EM to EL and the distance from shoulder to elbow (midpoint EM-EL)\n",
        "\n",
        "                            in_elbow_right = elbow_right + normal_vector1_right\n",
        "                            out_elbow_right = elbow_right - normal_vector1_right\n",
        "\n",
        "                            keypoints[20] = in_elbow_right.tolist()  # Right EM\n",
        "                            keypoints[21] = out_elbow_right.tolist()  # Right EL\n",
        "\n",
        "                            # Left EL, EM\n",
        "                            shoulder_left = np.array(keypoints[12])\n",
        "                            elbow_left = np.array(keypoints[13])\n",
        "                            wrist_left = np.array(keypoints[14])\n",
        "\n",
        "                            vector1_left = shoulder_left - elbow_left\n",
        "                            vector1_left_unit = vector1_left / np.linalg.norm(vector1_left)\n",
        "                            vector2_left = wrist_left - elbow_left\n",
        "                            vector2_left_unit = vector2_left / np.linalg.norm(vector2_left)\n",
        "                            normal_vector_left = np.cross(vector1_left, vector2_left)\n",
        "                            normal_vector_left_unit = normal_vector_left / np.linalg.norm(normal_vector_left)\n",
        "\n",
        "                            normal_vector1_left = normal_vector_left_unit * ((np.linalg.norm(shoulder_left - elbow_left) * (0.0632 / 2)) / 0.2655)\n",
        "\n",
        "                            in_elbow_left = elbow_left - normal_vector1_left\n",
        "                            out_elbow_left = elbow_left + normal_vector1_left\n",
        "\n",
        "                            keypoints[22] = in_elbow_left.tolist()  # Left EM\n",
        "                            keypoints[23] = out_elbow_left.tolist()  # Left EL\n",
        "\n",
        "                        # Calculate RS, US for each frame\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            index_right = np.array(keypoints_data1[frame_number][21])\n",
        "                            pinky_right = np.array(keypoints_data1[frame_number][19])\n",
        "                            wrist_right = np.array(keypoints[17])\n",
        "                            elbow_right = np.array(keypoints[16])\n",
        "\n",
        "                            vector_wrist_1 = index_right - pinky_right\n",
        "                            vector_wrist_unit_1 = vector_wrist_1 / np.linalg.norm(vector_wrist_1)\n",
        "\n",
        "                            vector_wrist_right = vector_wrist_unit_1 * ((np.linalg.norm(elbow_right - wrist_right) * (0.0351 / 2)) / 0.2312) #ratio between half the distance from US to RS and the distance from the elbow to the wrist\n",
        "                            in_wrist_right = wrist_right - vector_wrist_right\n",
        "                            out_wrist_right = wrist_right + vector_wrist_right\n",
        "\n",
        "                            keypoints[24] = in_wrist_right.tolist()  # Right US\n",
        "                            keypoints[25] = out_wrist_right.tolist()  # Right RS\n",
        "\n",
        "                            index_left = np.array(keypoints_data1[frame_number][20])\n",
        "                            pinky_left = np.array(keypoints_data1[frame_number][18])\n",
        "                            wrist_left = np.array(keypoints[14])\n",
        "                            elbow_left = np.array(keypoints[13])\n",
        "\n",
        "                            vector_wrist_2 = index_left - pinky_left\n",
        "                            vector_wrist_unit_2 = vector_wrist_2 / np.linalg.norm(vector_wrist_2)\n",
        "\n",
        "                            vector_wrist_left = vector_wrist_unit_2 * ((np.linalg.norm(elbow_left - wrist_left) * (0.0351 / 2)) / 0.2312)\n",
        "                            in_wrist_left = wrist_left - vector_wrist_left\n",
        "                            out_wrist_left = wrist_left + vector_wrist_left\n",
        "\n",
        "                            keypoints[26] = in_wrist_left.tolist()  # Left US\n",
        "                            keypoints[27] = out_wrist_left.tolist()  # Left RS\n",
        "\n",
        "                        # Calculate Right AC\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            IJ = np.array(keypoints[18])\n",
        "                            C7 = np.array(keypoints[9])\n",
        "                            T8 = np.array(keypoints[8])\n",
        "                            PX = np.array(keypoints[19])\n",
        "                            shoulder_right = np.array(keypoints[15])\n",
        "\n",
        "                            MidIJC7 = (IJ + C7) / 2\n",
        "                            MidPXT8 = (PX + T8) / 2\n",
        "\n",
        "                            Y = (MidIJC7 - MidPXT8) / np.linalg.norm(MidIJC7 - MidPXT8)\n",
        "\n",
        "                            IJC7 = (C7 - IJ) / np.linalg.norm(C7 - IJ)\n",
        "                            IJMid = (MidPXT8 - IJ) / np.linalg.norm(MidPXT8 - IJ)\n",
        "\n",
        "                            Z = np.cross(IJC7, IJMid) / np.linalg.norm(np.cross(IJC7, IJMid))\n",
        "\n",
        "                            X = np.cross(Y, Z) / np.linalg.norm(np.cross(Y, Z))\n",
        "\n",
        "                            A = np.column_stack((X, Y, Z))\n",
        "\n",
        "                            SJC_local = np.dot(A.T, (shoulder_right - IJ).reshape(-1, 1))\n",
        "\n",
        "                            AC_local = SJC_local - np.array([[12e-3], [-45e-3], [6e-3]])\n",
        "\n",
        "                            AC_r = IJ.reshape(-1, 1) + np.dot(A, AC_local)\n",
        "\n",
        "                            keypoints[28] = AC_r.flatten().tolist()  # Right AC\n",
        "\n",
        "                        # Calculate Left AC\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            IJ = np.array(keypoints[18])\n",
        "                            C7 = np.array(keypoints[9])\n",
        "                            T8 = np.array(keypoints[8])\n",
        "                            PX = np.array(keypoints[19])\n",
        "                            shoulder_left = np.array(keypoints[12])\n",
        "\n",
        "                            MidIJC7 = (IJ + C7) / 2\n",
        "                            MidPXT8 = (PX + T8) / 2\n",
        "\n",
        "                            Y = (MidIJC7 - MidPXT8) / np.linalg.norm(MidIJC7 - MidPXT8)\n",
        "\n",
        "                            IJC7 = (C7 - IJ) / np.linalg.norm(C7 - IJ)\n",
        "                            IJMid = (MidPXT8 - IJ) / np.linalg.norm(MidPXT8 - IJ)\n",
        "\n",
        "                            Z = np.cross(IJC7, IJMid) / np.linalg.norm(np.cross(IJC7, IJMid))\n",
        "\n",
        "                            X = np.cross(Y, Z) / np.linalg.norm(np.cross(Y, Z))\n",
        "\n",
        "                            A = np.column_stack((X, Y, Z))\n",
        "\n",
        "                            SJC_local = np.dot(A.T, (shoulder_left - IJ).reshape(-1, 1))\n",
        "\n",
        "                            AC_local = SJC_local - np.array([[12e-3], [-45e-3], [-6e-3]])\n",
        "\n",
        "                            AC_l = IJ.reshape(-1, 1) + np.dot(A, AC_local)\n",
        "\n",
        "                            keypoints[29] = AC_l.flatten().tolist()  # Left AC\n",
        "\n",
        "            # Save calculated keypoints in the dynamic .txt file\n",
        "            with open(dynamic_file, 'w') as f:\n",
        "                for frame_number, keypoints in keypoints_data.items():\n",
        "                    f.write(f\"Frame {frame_number}:\\n\")\n",
        "                    for keypoint_number, coordinates in keypoints.items():\n",
        "                        f.write(f\"Keypoint {keypoint_number}: {coordinates}\\n\")\n",
        "\n",
        "            print(\"New keypoints added to:\", dynamic_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-rWkShbBztq"
      },
      "outputs": [],
      "source": [
        "folder_keypoints = '/content/coordinates_VideoPose3D'\n",
        "folder_keypoints_1 = '/content/coordinates_MediaPipePose'\n",
        "\n",
        "# Calculate EL, EM, RS, US, AC for the static trial\n",
        "for root, dirs, files in os.walk(folder_keypoints):\n",
        "    for filename in files:\n",
        "        if filename.startswith('static') and filename.endswith('.txt'):\n",
        "            static_file = os.path.join(root, filename)\n",
        "            number = re.search(r'\\d+', filename).group()\n",
        "\n",
        "            keypoints_data = get_coordinates(static_file)\n",
        "\n",
        "            # Find corresponding static file in MediaPipePose folder\n",
        "            for root1, dirs1, files1 in os.walk(folder_keypoints_1):\n",
        "                for filename1 in files1:\n",
        "                    number1 = re.search(r'\\d+', filename1).group()\n",
        "                    if filename1.startswith('static') and filename1.endswith('.txt') and number1 == number:\n",
        "                        static_file1 = os.path.join(root1, filename1)\n",
        "                        keypoints_data1 = get_coordinates(static_file1)\n",
        "\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            # Right EL, EM\n",
        "                            shoulder_right = np.array(keypoints[15])\n",
        "                            elbow_right = np.array(keypoints[16])\n",
        "                            wrist_right = np.array(keypoints[17])\n",
        "\n",
        "                            vector1_right = shoulder_right - elbow_right\n",
        "                            vector1_right_unit = vector1_right / np.linalg.norm(vector1_right)\n",
        "                            vector2_right = wrist_right - elbow_right\n",
        "                            vector2_right_unit = vector2_right / np.linalg.norm(vector2_right)\n",
        "\n",
        "                            normal_vector_right = np.cross(vector1_right, vector2_right)\n",
        "                            normal_vector_right_unit = normal_vector_right / np.linalg.norm(normal_vector_right)\n",
        "\n",
        "                            normal_vector1_right = normal_vector_right_unit * ((np.linalg.norm(shoulder_right - elbow_right) * (0.0632 / 2)) / 0.2655)\n",
        "\n",
        "                            in_elbow_right = elbow_right + normal_vector1_right\n",
        "                            out_elbow_right = elbow_right - normal_vector1_right\n",
        "\n",
        "                            keypoints[20] = in_elbow_right.tolist()  # Right EM\n",
        "                            keypoints[21] = out_elbow_right.tolist()  # Right EL\n",
        "\n",
        "                            # Left EL, EM\n",
        "                            shoulder_left = np.array(keypoints[12])\n",
        "                            elbow_left = np.array(keypoints[13])\n",
        "                            wrist_left = np.array(keypoints[14])\n",
        "\n",
        "                            vector1_left = shoulder_left - elbow_left\n",
        "                            vector1_left_unit = vector1_left / np.linalg.norm(vector1_left)\n",
        "                            vector2_left = wrist_left - elbow_left\n",
        "                            vector2_left_unit = vector2_left / np.linalg.norm(vector2_left)\n",
        "                            normal_vector_left = np.cross(vector1_left, vector2_left)\n",
        "                            normal_vector_left_unit = normal_vector_left / np.linalg.norm(normal_vector_left)\n",
        "\n",
        "                            normal_vector1_left = normal_vector_left_unit * ((np.linalg.norm(shoulder_left - elbow_left) * (0.0632 / 2)) / 0.2655)\n",
        "\n",
        "                            in_elbow_left = elbow_left - normal_vector1_left\n",
        "                            out_elbow_left = elbow_left + normal_vector1_left\n",
        "\n",
        "                            keypoints[22] = in_elbow_left.tolist()  # Left EM\n",
        "                            keypoints[23] = out_elbow_left.tolist()  # Left EL\n",
        "\n",
        "                        # Calculate RS, US for each frame\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            index_right = np.array(keypoints_data1[frame_number][21])\n",
        "                            pinky_right = np.array(keypoints_data1[frame_number][19])\n",
        "                            wrist_right = np.array(keypoints[17])\n",
        "                            elbow_right = np.array(keypoints[16])\n",
        "\n",
        "                            vector_wrist_1 = index_right - pinky_right\n",
        "                            vector_wrist_unit_1 = vector_wrist_1 / np.linalg.norm(vector_wrist_1)\n",
        "\n",
        "                            vector_wrist_right = vector_wrist_unit_1 * ((np.linalg.norm(elbow_right - wrist_right) * (0.0351 / 2)) / 0.2312)\n",
        "                            in_wrist_right = wrist_right - vector_wrist_right\n",
        "                            out_wrist_right = wrist_right + vector_wrist_right\n",
        "\n",
        "                            keypoints[24] = in_wrist_right.tolist()  # Right US\n",
        "                            keypoints[25] = out_wrist_right.tolist()  # Right RS\n",
        "\n",
        "                            index_left = np.array(keypoints_data1[frame_number][20])\n",
        "                            pinky_left = np.array(keypoints_data1[frame_number][18])\n",
        "                            wrist_left = np.array(keypoints[14])\n",
        "                            elbow_left = np.array(keypoints[13])\n",
        "\n",
        "                            vector_wrist_2 = index_left - pinky_left\n",
        "                            vector_wrist_unit_2 = vector_wrist_2 / np.linalg.norm(vector_wrist_2)\n",
        "\n",
        "                            vector_wrist_left = vector_wrist_unit_2 * ((np.linalg.norm(elbow_left - wrist_left) * (0.0351 / 2)) / 0.2312)\n",
        "                            in_wrist_left = wrist_left - vector_wrist_left\n",
        "                            out_wrist_left = wrist_left + vector_wrist_left\n",
        "\n",
        "                            keypoints[26] = in_wrist_left.tolist()  # Left US\n",
        "                            keypoints[27] = out_wrist_left.tolist()  # Left RS\n",
        "\n",
        "                        # Calculate Right AC\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            IJ = np.array(keypoints[18])\n",
        "                            C7 = np.array(keypoints[9])\n",
        "                            T8 = np.array(keypoints[8])\n",
        "                            PX = np.array(keypoints[19])\n",
        "                            shoulder_right = np.array(keypoints[15])\n",
        "\n",
        "                            MidIJC7 = (IJ + C7) / 2\n",
        "                            MidPXT8 = (PX + T8) / 2\n",
        "\n",
        "                            Y = (MidIJC7 - MidPXT8) / np.linalg.norm(MidIJC7 - MidPXT8)\n",
        "\n",
        "                            IJC7 = (C7 - IJ) / np.linalg.norm(C7 - IJ)\n",
        "                            IJMid = (MidPXT8 - IJ) / np.linalg.norm(MidPXT8 - IJ)\n",
        "\n",
        "                            Z = np.cross(IJC7, IJMid) / np.linalg.norm(np.cross(IJC7, IJMid))\n",
        "\n",
        "                            X = np.cross(Y, Z) / np.linalg.norm(np.cross(Y, Z))\n",
        "\n",
        "                            A = np.column_stack((X, Y, Z))\n",
        "\n",
        "                            SJC_local = np.dot(A.T, (shoulder_right - IJ).reshape(-1, 1))\n",
        "\n",
        "                            AC_local = SJC_local - np.array([[12e-3], [-45e-3], [6e-3]])\n",
        "\n",
        "                            AC_r = IJ.reshape(-1, 1) + np.dot(A, AC_local)\n",
        "\n",
        "                            keypoints[28] = AC_r.flatten().tolist()  # Right AC\n",
        "\n",
        "                        # Calculate Left AC\n",
        "                        for frame_number, keypoints in keypoints_data.items():\n",
        "                            IJ = np.array(keypoints[18])\n",
        "                            C7 = np.array(keypoints[9])\n",
        "                            T8 = np.array(keypoints[8])\n",
        "                            PX = np.array(keypoints[19])\n",
        "                            shoulder_left = np.array(keypoints[12])\n",
        "\n",
        "                            MidIJC7 = (IJ + C7) / 2\n",
        "                            MidPXT8 = (PX + T8) / 2\n",
        "\n",
        "                            Y = (MidIJC7 - MidPXT8) / np.linalg.norm(MidIJC7 - MidPXT8)\n",
        "\n",
        "                            IJC7 = (C7 - IJ) / np.linalg.norm(C7 - IJ)\n",
        "                            IJMid = (MidPXT8 - IJ) / np.linalg.norm(MidPXT8 - IJ)\n",
        "\n",
        "                            Z = np.cross(IJC7, IJMid) / np.linalg.norm(np.cross(IJC7, IJMid))\n",
        "\n",
        "                            X = np.cross(Y, Z) / np.linalg.norm(np.cross(Y, Z))\n",
        "\n",
        "                            A = np.column_stack((X, Y, Z))\n",
        "\n",
        "                            SJC_local = np.dot(A.T, (shoulder_left - IJ).reshape(-1, 1))\n",
        "\n",
        "                            AC_local = SJC_local - np.array([[12e-3], [-45e-3], [-6e-3]])\n",
        "\n",
        "                            AC_l = IJ.reshape(-1, 1) + np.dot(A, AC_local)\n",
        "\n",
        "                            keypoints[29] = AC_l.flatten().tolist()  # Left AC\n",
        "\n",
        "            # Save calculated keypoints in the static .txt file\n",
        "            with open(static_file, 'w') as f:\n",
        "                for frame_number, keypoints in keypoints_data.items():\n",
        "                    f.write(f\"Frame {frame_number}:\\n\")\n",
        "                    for keypoint_number, coordinates in keypoints.items():\n",
        "                        f.write(f\"Keypoint {keypoint_number}: {coordinates}\\n\")\n",
        "\n",
        "            print(\"New keypoints added to:\", static_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRM5d8RPNrgp"
      },
      "source": [
        "**Step 4 -** Plot the skeleton-based model for a given frame of a given input video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTZoSvQSB0Ht"
      },
      "outputs": [],
      "source": [
        "#plot Hybrid\n",
        "\n",
        "import math\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "\n",
        "#function to calculate the mid point\n",
        "def calculate_midpoint(point1, point2):\n",
        "    x0, y0, z0 = point1\n",
        "    x1, y1, z1 = point2\n",
        "    midpoint = ((x0 + x1) / 2, (y0 + y1) / 2, (z0 + z1) / 2)\n",
        "    return midpoint\n",
        "\n",
        "file_name = input(\"Enter the directory of the file: \")\n",
        "frame_VideoPose3D = int(input(\"Enter the frame number: \"))\n",
        "\n",
        "keypoints_file = file_name\n",
        "keypoints_data = get_coordinates(keypoints_file)\n",
        "\n",
        "\n",
        "#Hybrid keypoints + additional estimated keypoints\n",
        "keypoints_to_name = {\n",
        "    1: 'pelvis',\n",
        "    2: 'right hip',\n",
        "    3: 'right knee',\n",
        "    4: 'right anke',\n",
        "    5: 'left hip',\n",
        "    6: 'left knee',\n",
        "    7: 'left ankle',\n",
        "    8: 'T8',\n",
        "    9: 'C7',\n",
        "    10: 'nose',\n",
        "    11: 'head',\n",
        "    12: 'left shoulder',\n",
        "    13: 'left elbow',\n",
        "    14: 'left wrist',\n",
        "    15: 'right shoulder',\n",
        "    16: 'right elbow',\n",
        "    17: 'right wrist',\n",
        "    18: 'IJ',\n",
        "    19: 'PX',\n",
        "    20: 'right EM',\n",
        "    21: 'right EL',\n",
        "    22: 'left EM',\n",
        "    23: 'left EL',\n",
        "    24: 'right US',\n",
        "    25: 'right RS',\n",
        "    26: 'left US',\n",
        "    27: 'left RS',\n",
        "    28: 'right AC',\n",
        "    29: 'left AC'\n",
        "}\n",
        "\n",
        "\n",
        "#skeleton for Hybrid keypoints\n",
        "skeleton_connections = [\n",
        "    (11, 10), (10, (18,9)),  #head\n",
        "    ((18, 9), (15, 28)), ((15,28), 16), (16, 17),  #right arm\n",
        "    ((18, 9), (12, 29)), ((12,29), 13), (13, 14),  #left arm\n",
        "    ((18, 9), (19, 8)), ((19,8), 1),  #trunk\n",
        "    (1, 2), (2, 3), (3, 4),  #right leg\n",
        "    (1, 5), (5, 6), (6, 7)  #left leg\n",
        "]\n",
        "\n",
        "\n",
        "#Hybrid referential system\n",
        "\n",
        "origin1 = np.array(keypoints_data[1][18]) #origin -  IJ\n",
        "mid_PX_T81 = (np.array(keypoints_data[1][19]) + np.array(keypoints_data[1][8]))/2 #midpoint of PX T8\n",
        "mid_IJ_C71 = (np.array(keypoints_data[1][18]) + np.array(keypoints_data[1][9]))/2 #midpoint of IJ C7\n",
        "y1= mid_IJ_C71 - mid_PX_T81\n",
        "y_axis1 = y1/ np.linalg.norm(y1)\n",
        "vector_1 = np.array(keypoints_data[1][18]) - np.array(keypoints_data[1][9]) #vector C7 - IJ\n",
        "vector_2 = mid_PX_T81 - np.array(keypoints_data[1][9]) #vector C7 - midpoint of PX T8\n",
        "vector_1_unit=vector_1/ np.linalg.norm(vector_1)\n",
        "vector_2_unit=vector_2/ np.linalg.norm(vector_2)\n",
        "z_axis1= -(np.cross(vector_1_unit, vector_2_unit)) / np.linalg.norm(np.cross(vector_1_unit, vector_2_unit)) #perpendicular vector to the plane formed by IJ, C7 e mid PX-T8\n",
        "x_axis1 = (np.cross(y_axis1, z_axis1)) / np.linalg.norm(np.cross(y_axis1, z_axis1))\n",
        "basis1 = np.array([[x_axis1[0], y_axis1[0], z_axis1[0]],\n",
        "                      [x_axis1[1], y_axis1[1], z_axis1[1]],\n",
        "                      [x_axis1[2], y_axis1[2], z_axis1[2]]])\n",
        "\n",
        "#transform the coordinates to the defined reference\n",
        "new_keypoints = {}\n",
        "for keypoint_number, coordinates in keypoints_data[frame_VideoPose3D].items():\n",
        "    pointP1 = np.array(coordinates)\n",
        "    new_point1 = (basis1.T).dot(pointP1 - origin1)\n",
        "    new_keypoints[keypoint_number] = new_point1\n",
        "\n",
        "\n",
        "desired_keypoints = [8, 9, 18, 19, 20, 21, 24, 25,28]\n",
        "desired_keypoints1 =[22,23,26,27,29]\n",
        "data_plot = []\n",
        "\n",
        "for keypoint_number, coordinates in new_keypoints.items():\n",
        "    x, y, z = coordinates\n",
        "    keypoint_name = keypoints_to_name.get(keypoint_number)\n",
        "    if keypoint_number == 8:\n",
        "        text = 'T8'\n",
        "    elif keypoint_number == 9:\n",
        "        text = 'C7'\n",
        "    elif keypoint_number == 18:\n",
        "        text = 'IJ'\n",
        "    elif keypoint_number == 19:\n",
        "        text = 'PX'\n",
        "    elif keypoint_number == 20:\n",
        "        text = 'EM'\n",
        "    elif keypoint_number == 21:\n",
        "        text = 'EL'\n",
        "    elif keypoint_number == 24:\n",
        "        text = 'US'\n",
        "    elif keypoint_number == 25:\n",
        "        text = 'RS'\n",
        "    elif keypoint_number == 28:\n",
        "        text = 'AC'\n",
        "    else:\n",
        "        text = None\n",
        "\n",
        "    trace = go.Scatter3d(\n",
        "        x=[x],\n",
        "        y=[y],\n",
        "        z=[z],\n",
        "        mode='markers+text' if text else 'markers',\n",
        "        marker=dict(\n",
        "            size=5,\n",
        "            color = 'orange' if (keypoint_number in desired_keypoints or keypoint_number in desired_keypoints1) else 'blue',\n",
        "            symbol='circle'\n",
        "        ),\n",
        "        text=[text],\n",
        "        textposition='bottom center',\n",
        "        textfont=dict(size=10),\n",
        "        name=f'{keypoint_number} - {keypoint_name}'\n",
        "    )\n",
        "    data_plot.append(trace)\n",
        "\n",
        "#connect the different keypoints\n",
        "for connection in skeleton_connections:\n",
        "    if isinstance(connection[0], tuple) and isinstance(connection[1], tuple): #when the first and the second are tupples\n",
        "        mid1 = calculate_midpoint(new_keypoints[connection[0][0]], new_keypoints[connection[0][1]])\n",
        "        mid2 = calculate_midpoint(new_keypoints[connection[1][0]], new_keypoints[connection[1][1]])\n",
        "        trace = go.Scatter3d(\n",
        "            x=[mid1[0], mid2[0]],\n",
        "            y=[mid1[1], mid2[1]],\n",
        "            z=[mid1[2], mid2[2]],\n",
        "            mode='lines',\n",
        "            line=dict(\n",
        "                color='blue',\n",
        "                width=2\n",
        "            ),\n",
        "            showlegend=False\n",
        "        )\n",
        "    elif isinstance(connection[0], tuple): #only the first is a tupple\n",
        "        mid = calculate_midpoint(new_keypoints[connection[0][0]], new_keypoints[connection[0][1]])\n",
        "        point = new_keypoints[connection[1]]\n",
        "        trace = go.Scatter3d(\n",
        "            x=[mid[0], point[0]],\n",
        "            y=[mid[1], point[1]],\n",
        "            z=[mid[2], point[2]],\n",
        "            mode='lines',\n",
        "            line=dict(\n",
        "                color='blue',\n",
        "                width=2\n",
        "            ),\n",
        "            showlegend=False\n",
        "        )\n",
        "    elif isinstance(connection[1], tuple): #only the second is a tupple\n",
        "        point = new_keypoints[connection[0]]\n",
        "        mid = calculate_midpoint(new_keypoints[connection[1][0]], new_keypoints[connection[1][1]])\n",
        "        trace = go.Scatter3d(\n",
        "            x=[point[0], mid[0]],\n",
        "            y=[point[1], mid[1]],\n",
        "            z=[point[2], mid[2]],\n",
        "            mode='lines',\n",
        "            line=dict(\n",
        "                color='blue',\n",
        "                width=2\n",
        "            ),\n",
        "            showlegend=False\n",
        "        )\n",
        "    else: #only one keypoint in each side\n",
        "        point1 = new_keypoints[connection[0]]\n",
        "        point2 = new_keypoints[connection[1]]\n",
        "        trace = go.Scatter3d(\n",
        "            x=[point1[0], point2[0]],\n",
        "            y=[point1[1], point2[1]],\n",
        "            z=[point1[2], point2[2]],\n",
        "            mode='lines',\n",
        "            line=dict(\n",
        "                color='blue',\n",
        "                width=2\n",
        "            ),\n",
        "            showlegend=False\n",
        "        )\n",
        "    data_plot.append(trace)\n",
        "\n",
        "#scale of the axis\n",
        "layout = go.Layout(\n",
        "    scene=dict(\n",
        "        xaxis=dict(title='X', range=[-1.2, 1.2]),\n",
        "        yaxis=dict(title='Y', range=[-1.2, 1.2]),\n",
        "        zaxis=dict(title='Z', range=[-1.2, 1.2]),\n",
        "        aspectmode='cube',\n",
        "        dragmode='orbit',\n",
        "        uirevision=True\n",
        "    ),\n",
        "    margin=dict(t=30, r=0, l=20, b=10)\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data_plot, layout=layout)\n",
        "\n",
        "\n",
        "#to select the angle of view\n",
        "angle_y = 10\n",
        "\n",
        "angle_rad = angle_y * (3.14159 / 180)\n",
        "\n",
        "camera_y_rotation = dict(\n",
        "    eye=dict(\n",
        "        x=0.7 * math.cos(angle_rad),\n",
        "        y=0,\n",
        "        z=0.7 * math.sin(angle_rad)\n",
        "    ),\n",
        "    up=dict(x=0, y=1, z=0),\n",
        "    center=dict(x=0, y=0, z=0)\n",
        ")\n",
        "\n",
        "fig.update_layout(scene_camera=camera_y_rotation)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}